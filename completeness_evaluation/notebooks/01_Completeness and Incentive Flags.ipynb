{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc1fd4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import datetime as dt\n",
    "from survey import Survey, nine_to_county, purp_num_to_name18, purp_num_to_name23, mode_num_to_name23, county_order\n",
    "sys.path.insert(0, r'Y:\\champ\\util\\pythonlib-migration\\master_versions\\misc_utils')\n",
    "from df_utils import df_to_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe5e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SURVEY_2023 = {'household':{'filepath_or_buffer':r'..\\..\\..\\..\\Deliverable_20241127\\hh.csv'},\n",
    "               'person':{'filepath_or_buffer':r'..\\..\\..\\..\\Deliverable_20241127\\person.csv'},\n",
    "               'day':{'filepath_or_buffer':r'..\\..\\..\\..\\Deliverable_20241127\\day.csv'},\n",
    "               'trip':{'filepath_or_buffer':r'..\\..\\..\\..\\Deliverable_20241127\\trip.csv'},\n",
    "               'vehicle':{'filepath_or_buffer':r'..\\..\\..\\..\\Deliverable_20241127\\vehicle.csv'},\n",
    "               'location':{'filepath_or_buffer':r'..\\..\\..\\..\\Deliverable_20241127\\location.csv'},\n",
    "               }\n",
    "OUTDIR = r'..\\..\\..\\..\\Review_20241127'\n",
    "INCENTIVES = r'<PATH>\\incentives_disaggregate.xlsx'\n",
    "ACS_MEANS_OF_TRANSPORTATION = r'<PATH>\\ACS\\ACSDT5Y2021.B08301-Data.csv'\n",
    "FIPS_COUNTIES   =['001','013','041','055','075','081','085','095','097']\n",
    "CONCURRENT_DAY_MIN = 4\n",
    "HOW='lenient'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c77dd6-2e25-40c9-9df8-84316e8be0ef",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "*Low income blockgroup*: a blockgroup in the 90th percentile of blockgroups by households with an annual income of \\$25,000 or less.\n",
    " - source: Table B19001\n",
    " - fields:\n",
    "   - B19001_001E (total)\n",
    "   - B19001_002E (lt \\$10k)\n",
    "   - B19001_003E (\\\\$10k-\\$15k)\n",
    "   - B19001_004E (\\\\$15k-\\$20k)\n",
    "   - B19001_005E (\\\\$20k-\\$25k)\n",
    "  \n",
    "*BIPOC blockgroup*: a blockgroup in the 90th percentile by percent of households in the blockgroup who are black, indigenous, person-of-color, and hispanic.  Only if not already labeled \"Low-Income Oversample\"\n",
    " - source: Table B03002\n",
    " - fields:\n",
    "    - B03002_001E (total)\n",
    "    - B03002_003E (white alone, not hispanic or latino)\n",
    "\n",
    "*Walk/bike/transit blockgroup*: segmented by county, a blockgroup in the 90th percentile of walk/bike/transit shares. Only if not already labeled \"Low-Income Oversample\" or \"BIPOC Oversample\".\n",
    " - source: Table B08301\n",
    " - fields:\n",
    "   - B08301_001E (total)\n",
    "   - B08301_010E (public transportation, excluding taxicab)\n",
    "   - B08301_018E (bicycle)\n",
    "   - B08301_019E (walk)\n",
    "\n",
    "## Sources\n",
    " - 2017-2021 5-year ACS\n",
    " - Public Use Microdata Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314eef6e-d80e-4949-97cf-ebc043f9e85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_mode = pd.read_csv(ACS_MEANS_OF_TRANSPORTATION, skiprows=[1])\n",
    "acs_mode = acs_mode[['GEO_ID','NAME','B08301_001E','B08301_010E','B08301_018E','B08301_019E']]\n",
    "acs_mode.insert(1, 'county', acs_mode['GEO_ID'].map(lambda x: x[11:14]))\n",
    "acs_mode.insert(2, 'bg', acs_mode['GEO_ID'].map(lambda x: int(x[9:])))\n",
    "acs_mode = acs_mode.loc[acs_mode['county'].isin(FIPS_COUNTIES)]\n",
    "acs_mode['tbw_share'] = acs_mode[['B08301_010E','B08301_018E','B08301_019E']].sum(axis=1) / acs_mode['B08301_001E']\n",
    "q90 = acs_mode.groupby('county', as_index=False)['tbw_share'].quantile(0.9).rename(columns={'tbw_share':'q90'})\n",
    "acs_mode = pd.merge(acs_mode, q90, on='county', how='left')\n",
    "acs_mode['tbw_flag'] = acs_mode['tbw_share'].ge(acs_mode['q90']) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea37166-38e1-43e5-bc08-2c3948eda0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "incentives = pd.read_excel(INCENTIVES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb04197-d8e2-4f83-8c15-b95760901388",
   "metadata": {},
   "outputs": [],
   "source": [
    "MISSING_CODES = [-1, 995,998,999] # missing, missing, don't know, prefer not to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa3efab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w2 = pd.ExcelWriter(r'Q:\\Data\\Surveys\\HouseholdSurveys\\MTC-SFCTA2022\\Review_20240809\\incentives_min_days_{}_{}_imputed.xlsx'.format(CONCURRENT_DAY_MIN, HOW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94e1418c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s23 = Survey(**SURVEY_2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ca623e",
   "metadata": {},
   "source": [
    "# SFCTA Completeness Evaluation\n",
    "## Trip Completeness\n",
    "add sfcta \"trip complete\" flag, cross-tab against rsg completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61bcb654",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip = pd.merge(s23.person[['person_id','diary_platform']], s23.trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a8749d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Create the trip flags\n",
    "flag = False\n",
    "trip_flags = []\n",
    "for c in ['o_purpose_category','d_purpose_category','mode_type',\n",
    "          'depart_hour','depart_minute','depart_seconds',\n",
    "          'arrive_hour','arrive_minute','arrive_second',\n",
    "          'o_lat','o_lon','d_lat','d_lon']:\n",
    "    trip_flags.append(c+'_complete')\n",
    "    trip[c+'_complete'] = ~(trip[c].isin([MISSING_CODES]) | pd.isnull(trip[c])) * 1\n",
    "    flag = flag | trip[c].isin([MISSING_CODES]) | pd.isnull(trip[c])\n",
    "\n",
    "# Flag the original\n",
    "trip['sfcta_is_complete'] = (~flag)*1\n",
    "trip['has_weight'] = trip['trip_weight'].gt(0) * 1\n",
    "trip['has_weight_rmove'] = trip['trip_weight_rmove_only'].gt(0) * 1\n",
    "s23.trip = pd.merge(s23.trip, trip[trip_flags+['trip_id','sfcta_is_complete','has_weight','has_weight_rmove']], on='trip_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c6e2ad2-6ba2-4c8b-9ecf-93351308b0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "365826    1\n",
       "365827    1\n",
       "365828    1\n",
       "365829    1\n",
       "365830    1\n",
       "Name: o_purpose_category_complete, Length: 365831, dtype: int32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip['o_purpose_category_complete']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353157c0",
   "metadata": {},
   "source": [
    "## Day Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1dc86f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Roll up the completeness analysis to the day.\n",
    "tmp = (s23.trip\n",
    "       .groupby(['hh_id','person_id','day_num'])\n",
    "       .agg({'sfcta_is_complete':'sum','trip_id':'count'})\n",
    "       .rename(columns={'sfcta_is_complete':'sfcta_num_trips'}))\n",
    "tmp['sfcta_day_trips_complete'] = (tmp['sfcta_num_trips'].eq(tmp['trip_id'])*1)\n",
    "day = pd.merge(s23.day, tmp[['sfcta_num_trips','sfcta_day_trips_complete']], \n",
    "               left_on=['hh_id','person_id','day_num'], right_index=True, how='left')\n",
    "\n",
    "day.loc[(day['made_travel'].eq(2) | day['num_reasons_no_travel'].gt(0)) & \n",
    "            pd.isnull(day['sfcta_day_trips_complete']), 'sfcta_num_trips'] = 0\n",
    "day.loc[(day['made_travel'].eq(2) | day['num_reasons_no_travel'].gt(0)) \n",
    "            & pd.isnull(day['sfcta_day_trips_complete']), 'sfcta_day_trips_complete'] = 1\n",
    "day = pd.merge(s23.person[['person_id','age','employment','is_proxy','has_proxy','student','diary_platform']],\n",
    "               day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95afe2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag=day['employment'].isin([1,2,3,7,8])\n",
    "flag_cols = []\n",
    "for c in ['telecommute_time']:\n",
    "    flag_cols.append(c+'_complete')\n",
    "    day[c+'_complete'] = ~(day['employment'].isin([1,2,3,7,8]) & (day[c].isin(MISSING_CODES) | pd.isnull(day[c]))) * 1\n",
    "    flag = flag & (day[c].isin(MISSING_CODES) | pd.isnull(day[c]))\n",
    "missing_telecommute_flag = flag\n",
    "\n",
    "day['sfcta_day_survey_complete'] = (~missing_telecommute_flag)*1\n",
    "day['sfcta_day_complete'] = (day['sfcta_day_survey_complete'].eq(1) & day['sfcta_day_trips_complete'].eq(1))*1\n",
    "day['has_weight'] = day['day_weight'].gt(0) * 1\n",
    "day['has_weight_rmove'] = day['day_weight_rmove_only'].gt(0) * 1\n",
    "\n",
    "# flag the original\n",
    "s23.day = pd.merge(s23.day, day[flag_cols + ['day_id','sfcta_num_trips','sfcta_day_survey_complete',\n",
    "                                 'sfcta_day_trips_complete','sfcta_day_complete','has_weight','has_weight_rmove']],\n",
    "                   on='day_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a67758",
   "metadata": {},
   "source": [
    "## Concurrent Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4e50671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that each travel_dow within a household is assigned the same `travel_date`\n",
    "s = day.groupby(['hh_id','travel_dow']).agg({'travel_date':'nunique'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cbee77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "concurrent_day = day.pivot_table(index=['hh_id','diary_platform'], \n",
    "                                 columns=['has_proxy','travel_dow'], \n",
    "                                 values='sfcta_day_complete', \n",
    "                                 aggfunc='sum').fillna(0).astype(int).reset_index().set_index('hh_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bad3e45a-aceb-45e2-a92f-1c13ab8cc0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "concurrent_weighted_day = day.pivot_table(index=['hh_id','diary_platform'], \n",
    "                                 columns=['has_weight','travel_dow'], \n",
    "                                 values='sfcta_day_complete', \n",
    "                                 aggfunc='sum').fillna(0).astype(int).reset_index().set_index('hh_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b7cc69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_size = s23.person.groupby('hh_id').agg({'person_id':'nunique',\n",
    "                                           'has_proxy':'sum'}).rename(columns={'person_id':'persons',\n",
    "                                                                               'has_proxy':'proxy_persons'})\n",
    "hh_size['non_proxy_persons'] = hh_size['persons'] - hh_size['proxy_persons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6908832",
   "metadata": {},
   "outputs": [],
   "source": [
    "concurrent_day['num_concurrent_non_proxy_days'] = (concurrent_day[0].eq(hh_size['non_proxy_persons'], axis=0)*1).sum(axis=1)\n",
    "concurrent_day['num_concurrent_total_days'] = ((concurrent_day[0]+concurrent_day[1]).eq(hh_size['persons'], axis=0)*1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9053a19-9b10-4e95-b895-f25701fc7549",
   "metadata": {},
   "outputs": [],
   "source": [
    "concurrent_weighted_day['num_concurrent_weighted_weekdays'] = ((concurrent_weighted_day[1].loc[:,2:4]).eq(hh_size['persons'], axis=0)*1).sum(axis=1)\n",
    "concurrent_weighted_day['num_concurrent_weighted_days'] = ((concurrent_weighted_day[1]).eq(hh_size['persons'], axis=0)*1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3773601",
   "metadata": {},
   "outputs": [],
   "source": [
    "concurrent_day['sfcta_pay_complete'] = ((concurrent_day['diary_platform'].eq('rmove') & \n",
    "                                         concurrent_day['num_concurrent_non_proxy_days'].ge(CONCURRENT_DAY_MIN) & \n",
    "                                         concurrent_day['num_concurrent_total_days'].ge(1)) | \n",
    "                                        (concurrent_day['diary_platform'].isin(['call','browser']) &\n",
    "                                         concurrent_day['num_concurrent_non_proxy_days'].ge(1) & \n",
    "                                         concurrent_day['num_concurrent_total_days'].ge(1)))* 1\n",
    "concurrent_day['sfcta_deliver_complete'] = (concurrent_day['num_concurrent_total_days'].ge(1)) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ae2e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# = concurrent_day.groupby('diary_platform').agg({('sfcta_pay_complete',''):'sum',\n",
    "#                                              ('sfcta_deliver_complete',''):'sum'})\n",
    "#t.loc['total'] = t.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ed7b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s = concurrent_day.loc[concurrent_day.index.isin(s23.hh.loc[s23.hh['home_county'].eq(6075),'hh_id'].tolist())].groupby('diary_platform').agg({('sfcta_pay_complete',''):'sum',\n",
    "#                                              ('sfcta_deliver_complete',''):'sum'})\n",
    "#s.loc['total'] = s.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "794803cd-63d0-4d47-915e-9ffafe639746",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = pd.DataFrame(concurrent_day[['num_concurrent_non_proxy_days','num_concurrent_total_days','sfcta_pay_complete','sfcta_deliver_complete']])\n",
    "j.columns=['num_concurrent_non_proxy_days','num_concurrent_total_days','sfcta_pay_complete','sfcta_deliver_complete']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03bcc895-7e10-44e5-a527-eff20eb79372",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pd.DataFrame(concurrent_weighted_day[['num_concurrent_weighted_weekdays','num_concurrent_weighted_days']])\n",
    "k.columns=['num_concurrent_weighted_weekdays','num_concurrent_weighted_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49733182-6cf9-4bbf-8976-b0165606cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "jk = pd.merge(j, k, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "887f1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = pd.merge(s23.hh, jk, left_on='hh_id', right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c478f9",
   "metadata": {},
   "source": [
    "## Person Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f842f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roll up to person level\n",
    "s23.person = pd.merge(s23.person,\n",
    "                      day.groupby('person_id', as_index=False)\n",
    "                         .agg({'sfcta_day_complete':'sum'})\n",
    "                         .rename(columns={'sfcta_day_complete':'sfcta_num_days_complete'}),\n",
    "                      how='left')\n",
    "person = s23.person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66d68de8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p16 = person['age'].ge(3)\n",
    "p18 = person['age'].ge(4)\n",
    "\n",
    "missing_person_ethnicity_flag = False | (p18 & (person['ethnicity_imputed'].eq('missing') | pd.isnull(person['ethnicity_imputed'])))\n",
    "missing_person_race_flag = False | (p18 & (person['race_imputed'].eq('missing') | pd.isnull(person['race_imputed'])))\n",
    "missing_person_gender_flag = person['gender_imputed'].eq('missing') | pd.isnull(person['gender_imputed'])\n",
    "missing_person_age_flag = False | person['age'].isin(MISSING_CODES) | pd.isnull(person['age'])\n",
    "missing_person_has_proxy_flag = False | person['has_proxy'].isin(MISSING_CODES) | pd.isnull(person['has_proxy'])\n",
    "\n",
    "missing_person_student_flag = False | (p16 & (person['student'].isin(MISSING_CODES) | pd.isnull(person['student'])))\n",
    "missing_person_employment_flag = False | (p16 & (person['employment'].isin(MISSING_CODES) | pd.isnull(person['employment'])))\n",
    "missing_person_can_drive_flag = False | (p16 & (person['can_drive'].isin(MISSING_CODES) | pd.isnull(person['can_drive'])))\n",
    "missing_person_education_flag = False | (p18 & (person['education'].isin(MISSING_CODES) | pd.isnull(person['education'])))\n",
    "\n",
    "# telework flag and work_loc, work_park flag\n",
    "# first check whether they're employed\n",
    "flag = (p16 & person['employment'].isin([1,2,3,7]))\n",
    "# then check that the do not ONLY work from home\n",
    "flag = flag & (person['job_type'].isin([1,2,4,5]))\n",
    "# for work_loc, check that they travel to work not never\n",
    "missing_work_loc_flag = flag & (person['commute_freq'].isin([1,2,3,4,5,6,7,8]))\n",
    "# check missing work park\n",
    "missing_work_park_flag = missing_work_loc_flag & (person['work_park'].isin(MISSING_CODES) | pd.isnull(person['work_park']))\n",
    "# check missing work loc\n",
    "for c in ['work_lat','work_lon']:\n",
    "    missing_work_loc_flag = missing_work_loc_flag & (person[c].isin(MISSING_CODES) | pd.isnull(person[c]))\n",
    "# for telework check that they go to the office 5 or fewer days a week\n",
    "missing_telework_flag = flag & (person['commute_freq'].isin([2,3,4,5,6,7,8,996]))\n",
    "# then check that they reported telework frequency\n",
    "missing_telework_flag = missing_telework_flag & (person['telework_freq'].isin(MISSING_CODES) | pd.isnull(person['telework_freq']))\n",
    "\n",
    "# school loc\n",
    "# check that person is student age, not cared for at home, attend dayschool outside home, or homeschooled\n",
    "flag = p16 & (person['school_type'].isin([3,5,6,7,10,11,12,13,997]))\n",
    "# then check that they go to a school in person\n",
    "flag = flag & person['school_attend'].isin([1,2])\n",
    "for c in ['school_lat','school_lon']:\n",
    "    flag = flag & (person[c].isin(MISSING_CODES) | pd.isnull(person[c]))\n",
    "missing_school_loc_flag = flag\n",
    "\n",
    "# transit pass flag  NOTE THERE IS ANOTHER transit_pass, which is not being checked\n",
    "missing_transit_pass_flag = person['clipper_card'].isin(MISSING_CODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a71f9e0-1a3b-404f-9fd7-aee63e9a8ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_person_any_flag = (missing_person_ethnicity_flag | missing_person_race_flag | missing_person_gender_flag | missing_person_age_flag | \n",
    "                          missing_person_employment_flag | missing_person_student_flag | missing_telework_flag | \n",
    "                          missing_school_loc_flag | missing_work_loc_flag | missing_work_park_flag | missing_transit_pass_flag | \n",
    "                          missing_person_has_proxy_flag | missing_person_can_drive_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f7d05da-fa72-48b0-bda4-8155f783f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_flags_priority =    [missing_person_race_flag,\n",
    "                            missing_person_ethnicity_flag,\n",
    "                            missing_person_gender_flag,\n",
    "                            missing_person_age_flag,\n",
    "                            missing_person_employment_flag,\n",
    "                            missing_telework_flag,\n",
    "                            missing_school_loc_flag,\n",
    "                            missing_work_park_flag,\n",
    "                            missing_person_has_proxy_flag,\n",
    "                            missing_person_can_drive_flag,\n",
    "                            missing_work_loc_flag,\n",
    "                            missing_person_student_flag,\n",
    "                            missing_transit_pass_flag,\n",
    "                           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9a6246b-2c77-466c-81da-f4713ed97c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['race_complete','ethnicity_complete','gender_complete','age_complete','employment_complete',\n",
    "         'telework_complete','school_loc_complete','work_park_complete','has_proxy_complete','can_drive_complete',\n",
    "         'work_loc_complete','student_complete','transit_pass_complete']\n",
    "for n, f in zip(names, person_flags_priority):\n",
    "    person[n] = (~f)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4789e1c-c689-4a74-ac8a-f2dd13ea6075",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_person_complete = person.groupby('hh_id')[names].sum().eq(person.groupby('hh_id').size(), axis='rows') * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f009c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "person['sfcta_person_days_complete'] = (((person['diary_platform'].isin(['browser','call']) | person['has_proxy'].eq(1)) & person['sfcta_num_days_complete'].ge(1)) |\n",
    "                                        (person['diary_platform'].eq('rmove') & person['sfcta_num_days_complete'].ge(CONCURRENT_DAY_MIN))) * 1\n",
    "person['sfcta_person_survey_complete'] = ~missing_person_any_flag*1\n",
    "person['sfcta_person_complete'] = (~missing_person_any_flag & person['sfcta_person_days_complete'].eq(1))*1\n",
    "person['has_weight'] = person['person_weight'].gt(0) * 1\n",
    "person['has_weight_rmove'] = person['person_weight_rmove_only'].gt(0) * 1\n",
    "# don't need to copy back because person is an alias of s23.person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235a502a-376a-4e17-b731-e00dabdf4cf5",
   "metadata": {},
   "source": [
    "### Person hard-to-reach\n",
    "- race_1: african american or black\n",
    "- race_2: american indian or alaska native\n",
    "- race_3: asian\n",
    "- race_4: native hawaiian or pacific islander\n",
    "- race_5: white\n",
    "- race_997: other\n",
    "- race_999: prefer not to answer\n",
    "- ethnicity_1: not hispanic\n",
    "- ethnicity_2: mexican, mexican american, chicano\n",
    "- ethnicity_3: puerto rican\n",
    "- ethnicity_4: cuban\n",
    "- ethnicity_997: other hispanic origin\n",
    "- ethnicity_999: prefer not to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce25e1bb-e8ce-48eb-86da-8207fcf36d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_flag = False\n",
    "for c in ['race_1','race_2','race_3','race_4','race_997', 'ethnicity_2','ethnicity_3', 'ethnicity_4','ethnicity_997']:\n",
    "    re_flag = re_flag | person[c].eq(1)\n",
    "person['sfcta_bipoc_flag'] = re_flag * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98f5ce3",
   "metadata": {},
   "source": [
    "## Household Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15f5d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = (s23.person\n",
    "       .groupby('hh_id', as_index=False)\n",
    "       .agg({'sfcta_person_complete':'sum', 'person_id':'count','sfcta_bipoc_flag':'sum'})\n",
    "       .rename(columns={'sfcta_person_complete':'sfcta_num_persons_complete',\n",
    "                        'person_id':'persons'})\n",
    "       )\n",
    "tmp['sfcta_hh_persons_complete'] = (tmp['sfcta_num_persons_complete'].eq(tmp['persons']))*1\n",
    "tmp['sfcta_bipoc_flag'] = tmp['sfcta_bipoc_flag'].ge(1) * 1\n",
    "hh = pd.merge(hh, tmp[['hh_id','sfcta_num_persons_complete','sfcta_hh_persons_complete','sfcta_bipoc_flag']],\n",
    "              on='hh_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2648439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = False\n",
    "for c in ['num_workers','num_adults','num_kids', #'income_detailed','income_broad',\n",
    "          'num_workers','num_vehicles','home_lat','home_lon']:\n",
    "    hh[c+'_complete'] = ~(hh[c].isin(MISSING_CODES) | pd.isnull(hh[c])) * 1\n",
    "    flag = flag | hh[c].isin(MISSING_CODES) | pd.isnull(hh[c])\n",
    "\n",
    "missing_hh_income_flag = hh['income_imputed'].eq('missing') | pd.isnull(hh['income_imputed'])\n",
    "missing_hh_basic_flag = flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3b13587-d0f8-4be4-8148-af09f4c2347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = pd.merge(hh, hh_person_complete, how='left', left_on='hh_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e81d3238",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh['sfcta_hh_survey_complete'] = ~(missing_hh_basic_flag | missing_hh_income_flag)*1\n",
    "hh['sfcta_hh_complete'] = (hh['sfcta_hh_survey_complete'].eq(1) & hh['sfcta_hh_persons_complete'].eq(1))*1\n",
    "hh['has_weight'] = hh['hh_weight'].gt(0) * 1\n",
    "hh['has_weight_rmove'] = hh['hh_weight_rmove_only'].gt(0) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8840e679-7bb6-4d53-8eb0-76c16c216356",
   "metadata": {},
   "source": [
    "### Household hard-to-reach\n",
    "- income_broad = 1: under \\$25,000\n",
    "- income_detailed in (1, 2): under \\$25,000\n",
    "- income_followup = 1: under \\$25,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "612a9fcb-dc1c-4605-8dd7-d79d2a1ac013",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowinc_flag = hh['income_broad'].eq(1) | hh['income_followup'].eq(1) | hh['income_detailed'].isin([1,2])\n",
    "hh['sfcta_lowinc_flag'] = lowinc_flag * 1\n",
    "hh.insert(1,'season',(hh['first_travel_date'].lt('2023-07-01')*1).map(lambda x: {0:'fall',1:'spring'}[x]))\n",
    "hh = pd.merge(hh, acs_mode[['county','bg','tbw_flag']].rename(columns={'bg':'home_bg_2020','tbw_flag':'sfcta_tbw_flag'}),\n",
    "              how='left')\n",
    "hh['sfcta_hard_to_reach'] = hh[['sfcta_bipoc_flag','sfcta_lowinc_flag','sfcta_tbw_flag']].sum(axis=1).ge(1)*1\n",
    "\n",
    "s23.hh = hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cee29433-ff58-487e-a720-4796bb850563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_travel_date</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>2 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023-06-09</td>\n",
       "      <td>131 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2023-11-16</td>\n",
       "      <td>5 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2023-11-21</td>\n",
       "      <td>6 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2023-12-14</td>\n",
       "      <td>5 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2023-12-19</td>\n",
       "      <td>19 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2024-01-13</td>\n",
       "      <td>3 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_travel_date      gap\n",
       "0         2023-05-07   2 days\n",
       "32        2023-06-09 131 days\n",
       "62        2023-11-16   5 days\n",
       "63        2023-11-21   6 days\n",
       "81        2023-12-14   5 days\n",
       "82        2023-12-19  19 days\n",
       "89        2024-01-13   3 days"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.DataFrame(pd.to_datetime(hh.groupby('first_travel_date').size().index))\n",
    "dates['gap'] =  dates['first_travel_date'].shift(-1) - dates['first_travel_date']\n",
    "dates.loc[dates['gap'].gt(dt.timedelta(days=1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dded7a26-e7b8-4616-b7df-e5bbb23b3538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">hh_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_travel_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>23100065</td>\n",
       "      <td>23803687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>23000023</td>\n",
       "      <td>23041498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      hh_id          \n",
       "                        min       max\n",
       "first_travel_date                    \n",
       "False              23100065  23803687\n",
       "True               23000023  23041498"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh.groupby([hh['first_travel_date'].lt('2023-07-01')]).agg({'hh_id':['min','max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7982a88-0034-47e9-b3a4-f5799cd9d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "incentives['season'] = (incentives['hh_id'].lt(23100000) * 1).map(lambda x: {0:'fall', 1:'spring'}[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "012991b0-3cfd-4374-b0bb-25dfd7418964",
   "metadata": {},
   "outputs": [],
   "source": [
    "incentives = pd.merge(incentives, hh[['hh_id','num_people', 'num_surveyable', 'num_participants',\n",
    "                                      'num_adults', 'num_kids','first_travel_date', 'diary_platform',\n",
    "                                      'sfcta_bipoc_flag','sfcta_lowinc_flag','sfcta_tbw_flag',\n",
    "                                      'sfcta_hard_to_reach','sfcta_hh_complete','sfcta_num_persons_complete']],\n",
    "                      how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "628f70ca-5896-4f64-953a-25ac02fa47cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "incentives['per_person1'] = incentives['total_incentive_before_discount'] / incentives['num_participants']\n",
    "incentives['per_person2'] = incentives['total_incentive_before_discount'] / incentives['sfcta_num_persons_complete']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e951e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = {0: 'incomplete',\n",
    "      1: 'complete',\n",
    "      995: 'missing',\n",
    "      998: 'dont know',\n",
    "      999: 'prefer not to answer'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0881ff35-4333-42e4-a94e-02075fa9cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=0,\n",
    "                  index=['hh','person','day','trip'], \n",
    "                  columns=['complete_has_weight','complete_no_weight','incomplete_has_weight','incomplete_no_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69c3fa4c-dbbb-4a02-8bca-bcf7c932a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {(0,0):'incomplete_no_weight',\n",
    "          (0,1):'incomplete_has_weight',\n",
    "          (1,0):'complete_no_weight',\n",
    "          (1,1):'complete_has_weight',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0bf8651-9e74-478a-95af-53c9ba7c38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_h = s23.hh.groupby(['sfcta_hh_complete','has_weight']).agg({'hh_id':'count'}).T.rename(index={'hh_id':'hh'})\n",
    "_p = s23.person.groupby(['sfcta_person_complete','has_weight']).agg({'person_id':'count'}).T.rename(index={'person_id':'person'})\n",
    "_d = s23.day.groupby(['sfcta_day_complete','has_weight']).agg({'day_id':'count'}).T.rename(index={'day_id':'day'})\n",
    "_t = s23.trip.groupby(['sfcta_is_complete','has_weight']).agg({'trip_id':'count'}).T.rename(index={'trip_id':'trip'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fa4eeff-25bd-4e93-8f15-862ddc22e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [_h,_p,_d,_t]:\n",
    "    new_cols = []\n",
    "    for c in x.columns:\n",
    "        new_cols.append(rename[c])\n",
    "    x.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2482a309-7932-4499-ada5-3221e216cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.update(_h)\n",
    "df.update(_p)\n",
    "df.update(_d)\n",
    "df.update(_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99ae70d2-fc06-4352-ab5d-379e28a41303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('completeness_by_weight_status.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "301fa0a0-97b6-4c24-9bdf-06f4b7d2fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = pd.DataFrame(index=[n.replace('_complete','') for n in names],\n",
    "                  columns=['complete_has_weight','complete_no_weight','complete_total',\n",
    "                           'incomplete_has_weight','incomplete_no_weight','incomplete_total',\n",
    "                           'cumulative_complete_has_weight','cumulative_complete_no_weight','cumulative_complete_total'])\n",
    "cumulative = 1\n",
    "for n in names:\n",
    "    cumulative = cumulative * person[n]\n",
    "    x = person.groupby([n, 'has_weight']).agg({'person_id':'size'}).T.rename(index={'person_id':n.replace('_complete','')})\n",
    "    new_cols = []\n",
    "    for c in x.columns:\n",
    "        new_cols.append(rename[c])\n",
    "    x.columns = new_cols\n",
    "    \n",
    "    y = person.groupby([cumulative, 'has_weight']).agg({'person_id':'size'}).T.rename(index={'person_id':n.replace('_complete','')})\n",
    "    new_cols = []\n",
    "    for c in y.columns:\n",
    "        new_cols.append('cumulative_'+rename[c])\n",
    "    y.columns = new_cols\n",
    "    pc.update(x)\n",
    "    pc.update(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ffea134-f341-4d8e-8cbc-791f6ab8dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91bc246c-fe1b-4f02-bd30-5a6ae5245a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc['complete_total'] = pc['complete_has_weight'] + pc['complete_no_weight']\n",
    "pc['incomplete_total'] = pc['incomplete_has_weight'] + pc['incomplete_no_weight']\n",
    "pc['cumulative_complete_total'] = pc['cumulative_complete_has_weight'] + pc['cumulative_complete_no_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db97f9c9-e203-43d5-b89c-87c5b8bb91fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpc = pd.DataFrame(index=[n.replace('_complete','') for n in names],\n",
    "                   columns=['complete_has_weight','complete_no_weight','complete_total',\n",
    "                            'incomplete_has_weight','incomplete_no_weight','incomplete_total',\n",
    "                            'cumulative_complete_has_weight','cumulative_complete_no_weight','cumulative_complete_total'])\n",
    "cumulative = 1\n",
    "for n in names:\n",
    "    cumulative = cumulative * hh[n]\n",
    "    x = hh.groupby([n, 'has_weight']).agg({'hh_id':'size'}).T.rename(index={'hh_id':n.replace('_complete','')})\n",
    "    new_cols = []\n",
    "    for c in x.columns:\n",
    "        new_cols.append(rename[c])\n",
    "    x.columns = new_cols\n",
    "    \n",
    "    y = hh.groupby([cumulative, 'has_weight']).agg({'hh_id':'size'}).T.rename(index={'hh_id':n.replace('_complete','')})\n",
    "    new_cols = []\n",
    "    for c in y.columns:\n",
    "        new_cols.append('cumulative_'+rename[c])\n",
    "    y.columns = new_cols\n",
    "    hpc.update(x)\n",
    "    hpc.update(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ae5a7d9-0d59-46c1-a5a1-74bc4e33cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpc.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf29e512-e016-400a-b9bb-85d55a0e8ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpc['complete_total'] = hpc['complete_has_weight'] + hpc['complete_no_weight']\n",
    "hpc['incomplete_total'] = hpc['incomplete_has_weight'] + hpc['incomplete_no_weight']\n",
    "hpc['cumulative_complete_total'] = hpc['cumulative_complete_has_weight'] + hpc['cumulative_complete_no_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6dfa7f31-40c4-443c-a91e-5b02a31bced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s23.hh.to_csv(os.path.join(OUTDIR,'flagged','hh.csv'), index=False)\n",
    "s23.person.to_csv(os.path.join(OUTDIR,'flagged','person.csv'), index=False)\n",
    "s23.day.to_csv(os.path.join(OUTDIR,'flagged','day.csv'), index=False)\n",
    "s23.trip.to_csv(os.path.join(OUTDIR,'flagged','trip.csv'), index=False)\n",
    "incentives.to_csv(os.path.join(OUTDIR,'flagged','incentives.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "43bbd076-58af-44d8-9df5-dea8dee3be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.to_csv(os.path.join(OUTDIR,'flagged','person_completeness.csv'))\n",
    "hpc.to_csv(os.path.join(OUTDIR,'flagged','household_person_completeness.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "11e0c7aa-5edc-4995-8f12-a0281d212ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh.loc[hh['hh_id'].isin(person.loc[person['has_weight'].eq(0) & person['can_drive_complete'].eq(0),'hh_id'].tolist())].to_csv(os.path.join(OUTDIR,'hh_with_persons_missing_weights.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
